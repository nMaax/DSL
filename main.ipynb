{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Lab: Process and methods - Winter Call 2024/25\n",
    "\n",
    "Author: Massimiliano Carli\n",
    "\n",
    "Project: Age estimation from speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from IPython.display import display  # to display variables in a \"nice\" way\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# My models and features\n",
    "from utils.filenames_generators import *\n",
    "from utils.plotters import *\n",
    "from utils.feature_engineering.wave_spectrogram_extractors import *\n",
    "from utils.feature_engineering.feature_engineering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True # best practice for avoiding making deep copies rather than views of DataFrames and Series \n",
    "pd.options.display.max_rows = 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the copy-on-write (CoW) best practice, see the [related Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable//user_guide/copy_on_write.html), it will become the default behaviour from Pandas 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling_rate: 22050\n",
      "n_mfcc: 20\n",
      "n_mels: 20\n",
      "num_silence_frames: 20\n"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "n_mfcc = config[\"n_mfcc\"]\n",
    "n_mels = config[\"n_mels\"]\n",
    "sampling_rate = config[\"sampling_rate\"]\n",
    "num_silence_frames = config[\"num_silence_frames\"]\n",
    "\n",
    "print(f\"sampling_rate: {sampling_rate}\")\n",
    "print(f\"n_mfcc: {n_mfcc}\")\n",
    "print(f\"n_mels: {n_mfcc}\")\n",
    "print(f\"num_silence_frames: {num_silence_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('data/development.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = compute_waves(data, sr=sampling_rate, filter=None) # Estimated 2m for computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = compute_spectrograms(data, sr=sampling_rate) # Estimated 3m for computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drop_unused_columns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode_gender(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode_ethnicity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = floatize_tempo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = comb_precomp(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = log_mel_spec(data, S=True, sr=sampling_rate, n_mels=n_mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mfcc(data, S=True, sr=sampling_rate, n_mfcc=n_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = silence_duration_contour(data, sr=sampling_rate, num_silence_frames=num_silence_frames) # Estimated 3m to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save features for avoiding computation later***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = generate_dataset_filename()\n",
    "data.drop(columns=['wave', 'spectrogram', 'melspectrogram', 'log_melspectrogram']).to_csv(filename)\n",
    "print(f\"Data saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously computed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\development-20250128-114352.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_computed_features = [\n",
    "    'mean_pitch',\n",
    "    'max_pitch',\n",
    "    'min_pitch',\n",
    "    'jitter',\n",
    "    'shimmer',\n",
    "    'energy',\n",
    "    'zcr_mean',\n",
    "    'spectral_centroid_mean',\n",
    "    'tempo',\n",
    "    'hnr',\n",
    "    'num_words',\n",
    "    'num_characters',\n",
    "    'num_pauses',\n",
    "    'silence_duration',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pre_comp_features = [\n",
    "    'duration',\n",
    "    'intensity',\n",
    "    'characters_per_word',\n",
    "    'words_per_second',\n",
    "    'pitch_range',\n",
    "    'mean_to_max_pitch_ratio',\n",
    "    'energy_to_duration_ratio',\n",
    "    'energy_to_silence_ratio',\n",
    "    'num_words_per_silence',\n",
    "    'silence_ratio',\n",
    "    'gender_female',\n",
    "    'gender_male',\n",
    "    'ethnicity_english',\n",
    "    'ethnicity_igbo',\n",
    "    'ethnicity_others',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_melspec_mean_features = [f'log_melspec_mean_{i}' for i in range(n_mels)]\n",
    "log_melspec_median_features = [f'log_melspec_median_{i}' for i in range(n_mels)]\n",
    "log_melspec_std_features = [f'log_melspec_std_{i}' for i in range(n_mels)]\n",
    "log_melspec_overall_features = [\n",
    "    'log_melspec_mean', \n",
    "    'log_melspec_median', \n",
    "    'log_melspec_std', \n",
    "    'log_melspec_skewness', \n",
    "    'log_melspec_kurtosis'\n",
    "]\n",
    "log_melspec_mean_delta_features = [f'delta_log_melspec_mean_{i}' for i in range(n_mfcc)]\n",
    "log_melspec_std_delta_features = [f'delta_log_melspec_mean_{i}' for i in range(n_mfcc)]\n",
    "log_melspec_delta_features = log_melspec_mean_delta_features + log_melspec_std_delta_features\n",
    "\n",
    "log_melspec_features = log_melspec_mean_features + log_melspec_std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_mean_features = [f'mfcc_mean_{i}' for i in range(n_mfcc)]\n",
    "mfcc_median_features = [f'mfcc_median_{i}' for i in range(n_mfcc)]\n",
    "mfcc_std_features = [f'mfcc_std_{i}' for i in range(n_mfcc)]\n",
    "mfcc_overall_features = [\n",
    "    'mfcc_mean',\n",
    "    'mfcc_median',\n",
    "    'mfcc_std',\n",
    "    'mfcc_skewness',\n",
    "    'mfcc_kurtosis',\n",
    "]\n",
    "mfcc_mean_delta_features = [f'delta_mfcc_mean_{i}' for i in range(n_mfcc)]\n",
    "mfcc_std_delta_features = [f'delta_mfcc_mean_{i}' for i in range(n_mfcc)]\n",
    "mfcc_delta_features = mfcc_mean_delta_features + mfcc_std_delta_features\n",
    "\n",
    "mfcc_features = mfcc_mean_features + mfcc_std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_duration_frames_features = [f'silence_duration_frame_{i}' for i in range(num_silence_frames)]\n",
    "silence_ratio_on_frames_features = [f'silence_ratio_on_frame_{i}' for i in range(num_silence_frames)]\n",
    "silence_duration_frames_overall_features = [\n",
    "    'silence_duration_frames_mean',\n",
    "    'silence_duration_frames_median',\n",
    "    'silence_duration_frames_std',\n",
    "]\n",
    "\n",
    "silence_duration_countour_features = silence_duration_frames_overall_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pre_computed_features + comb_pre_comp_features + mfcc_features + log_melspec_features + silence_duration_countour_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'age'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXtreme Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters: {'colsample_bytree': 0.4, 'gamma': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'reg_alpha': 0, 'reg_lambda': 100, 'subsample': 0.4}\n",
    "best_xgb = XGBRegressor(colsample_bytree=0.4, gamma=0.8, learning_rate=0.05, max_depth=5, n_estimators=1000, reg_alpha=0, reg_lambda=100, subsample=0.4, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    \n",
    "    # Tree structure\n",
    "    'max_depth': [3, 5],                        # Maximum depth of a tree\n",
    "    'n_estimators': [500, 1000],         # Number of trees\n",
    "    'gamma': [0.3, 0.5, 0.8],                   # Minimum loss reduction to split node\n",
    "    \n",
    "    # Learning rate\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "\n",
    "    # Regularization hyperparameters\n",
    "    'reg_alpha' : [0, 10, 100],                 # L1 regularization\n",
    "    'reg_lambda': [0, 10, 100],                 # L2 regularization\n",
    "\n",
    "    # Sampling hyperparameters\n",
    "    'subsample':        [0.4, 0.6, 0.8],        # Fraction of samples to use for fitting the base learners\n",
    "    'colsample_bytree': [0.4, 0.6, 0.8],        # Fraction of features to use for fitting the base learners\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=seed)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {grid_search_xgb.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_xgb = best_xgb.predict(X_test)\n",
    "y_test_pred_xgb = np.round(y_test_pred_xgb)\n",
    "test_rmse_xgb = root_mean_squared_error(y_true=y_test, y_pred=y_test_pred_xgb)\n",
    "\n",
    "print(f\"Testing RMSE: {test_rmse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "olr = LinearRegression()\n",
    "olr.fit(X_train, y_train)\n",
    "y_test_pred_olr = olr.predict(X_test)\n",
    "y_test_pred_olr = np.round(y_test_pred_olr)\n",
    "test_rmse_olr = root_mean_squared_error(y_true=y_test, y_pred=y_test_pred_olr)\n",
    "\n",
    "print(f\"Testing RMSE: {test_rmse_olr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Choose the model you prefer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Store the model for later use***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models\\\\' + generate_model_filename(model) + '.joblib'\n",
    "joblib.dump(model, filename)\n",
    "print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Run the model on the prediction set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_pipeline(\n",
    "        df, \n",
    "        data_directory='data/audios_evaluation',\n",
    "        sr=sampling_rate,\n",
    "        n_mels=n_mels,\n",
    "        n_mfcc=n_mfcc,\n",
    "        num_silence_frames=num_silence_frames,\n",
    "    ):\n",
    "    \n",
    "    data = df.copy()\n",
    "    data['gender'] = data['gender'].replace({'famale': 'female'}) # Fix typo\n",
    "\n",
    "    # Compute waves and spectogram\n",
    "    data = compute_waves(data, sr=sr, filter=None, directory=data_directory)\n",
    "    data = compute_spectrograms(data, sr=sr)\n",
    "    \n",
    "    # Extract and clean features\n",
    "    data = drop_unused_columns(data)\n",
    "    data = encode_gender(data)\n",
    "    data = encode_ethnicity(data)\n",
    "    data = floatize_tempo(data)\n",
    "    data = comb_precomp(data)\n",
    "    data = log_mel_spec(data, n_mels=n_mels)\n",
    "    data = mfcc(data, S=True, sr=sr, n_mfcc=n_mfcc)\n",
    "    data = silence_duration_contour(data, num_silence_frames=num_silence_frames)\n",
    "    data = spectral(data, S=True, sr=sr)\n",
    "    data = rms(data, S=True)\n",
    "    data = chroma(data, sr=sampling_rate)\n",
    "    \n",
    "    data = data.copy()\n",
    "    return data\n",
    "\n",
    "def target_engineering_pipeline(y):\n",
    "    #y = np.expm1(y)\n",
    "    y = np.round(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, features, eval_df=None, eval_path='data/evaluation.csv', index_col='Id', save_to_csv=True):\n",
    "    \n",
    "    # Load evaluation data\n",
    "    if eval_df is None or eval_df.columns.size == 18:\n",
    "        eval_df = pd.read_csv(eval_path, index_col=index_col)\n",
    "        eval_df = feature_engineering_pipeline(eval_df)\n",
    "    \n",
    "    eval_df = eval_df[features]\n",
    "\n",
    "    # Run model and predict\n",
    "    prediction = model.predict(eval_df)\n",
    "    prediction = target_engineering_pipeline(prediction)\n",
    "    prediction = pd.Series(prediction, index=eval_df.index)\n",
    "\n",
    "    # Save results\n",
    "    if save_to_csv:\n",
    "        filename = 'predictions\\\\' + 'prediction-' + generate_model_filename(model) + '.csv'\n",
    "        prediction.to_csv(filename, header=['Predicted'], index_label='Id')\n",
    "        print(f\"Prediction saved as: {filename}\")\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Precompute eval features\n",
    "# eval_df = pd.read_csv('data/evaluation.csv', index_col='Id')\n",
    "# eval_df = feature_engineering_pipeline(eval_df)\n",
    "# eval_df.drop(columns=['wave', 'spectrogram', 'melspectrogram', 'log_melspectrogram']).to_csv('data/evaluation-precomputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('data/evaluation-precomputed.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model=model, features=features, eval_df=eval_df, save_to_csv=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
